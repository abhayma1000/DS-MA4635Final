{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3baa130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "if os.path.exists(\"/home/abhay/.cache/kagglehub/datasets/salvatorerastelli/spotify-and-youtube/versions/2\"):\n",
    "    path = \"/home/abhay/.cache/kagglehub/datasets/salvatorerastelli/spotify-and-youtube/versions/2\"\n",
    "else:\n",
    "    path = kagglehub.dataset_download(\"salvatorerastelli/spotify-and-youtube\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_data = pd.read_csv(path + \"/Spotify_Youtube.csv\")\n",
    "\n",
    "train, test = train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c64fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import copy\n",
    "\n",
    "def clip(x, mean, std, num_std):\n",
    "    if x > mean + num_std * std:\n",
    "        return mean + num_std * std\n",
    "    elif x < mean - num_std * std:\n",
    "        return mean - num_std * std\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def get_train_df(df: pd.DataFrame, numerical_predictors: list, categorical_predictors: list, output: str):\n",
    "    before_dropped_len = len(df)\n",
    "\n",
    "    all_cols = numerical_predictors + categorical_predictors + [output]\n",
    "    all_numerical_cols = numerical_predictors + [output]\n",
    "\n",
    "    df = df.dropna(subset=all_cols)\n",
    "    df = df.copy()\n",
    "\n",
    "    print(f'Dropped {before_dropped_len - len(df)} rows with NaN values. Remaining rows: {len(df)}')\n",
    "\n",
    "    # Filter out rows in train where Views > mean + std\n",
    "    output_mean = df[output].mean()\n",
    "    output_std = df[output].std()\n",
    "    df = df[df[output] <= output_mean + output_std]\n",
    "\n",
    "    df[output].hist(bins=100)\n",
    "    plt.title(f\"Distribution of {output} after filtering\")\n",
    "    plt.show()\n",
    "\n",
    "    total_count = 0\n",
    "\n",
    "    for col in numerical_predictors:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        count = ((df[col] - mean) / std).abs() > 3\n",
    "        # print(f'Column {col} has {count.sum()} values more than 3 standard deviations from the mean')\n",
    "        total_count += count.sum()\n",
    "\n",
    "        # print(f\"{col} max before clipping:\", df[col].max())\n",
    "        # print(f\"{col} min before clipping:\", df[col].min())\n",
    "        # print(f\"{col} mean before clipping:\", df[col].mean())\n",
    "        # print(f\"{col} std before clipping:\", df[col].std())\n",
    "\n",
    "        df[col] = df[col].apply(lambda x: clip(x, mean, std, 2))  # Ensure reassignment\n",
    "\n",
    "        # print(f\"{col} max after clipping:\", df[col].max())\n",
    "        # print(f\"{col} min after clipping:\", df[col].min())\n",
    "    \n",
    "    print(f'Total outliers: {total_count}. Percentage: {total_count / len(df) * 100:.2f}%')\n",
    "    \n",
    "\n",
    "    if output == \"Views\":\n",
    "        df[output] = df[output].apply(lambda x: np.sqrt(x))\n",
    "    \n",
    "    if 'Duration_ms' in df.columns:\n",
    "        df['Duration_ms'] = df['Duration_ms'].apply(lambda x: np.sqrt(x))\n",
    "    if 'Key' in df.columns:\n",
    "        df['key_angle'] = df['Key'].apply(lambda x: x * 30)\n",
    "        df['key_height'] = df['key_angle'].apply(lambda x: np.sin(np.radians(x)))\n",
    "        df['key_width'] = df['key_angle'].apply(lambda x: np.cos(np.radians(x)))\n",
    "        numerical_predictors.remove(\"Key\")\n",
    "        numerical_predictors.append(\"key_height\")\n",
    "        numerical_predictors.append(\"key_width\")\n",
    "\n",
    "    df['mean_views'] = df['Artist'].map(df.groupby('Artist')['Views'].mean()).apply(np.sqrt)\n",
    "\n",
    "\n",
    "    nrows = int(len(numerical_predictors) / 4) + 1\n",
    "    fig, axes = plt.subplots(nrows, ncols=4, figsize=(60, 20))\n",
    "    count = 0\n",
    "    for row in range(nrows):\n",
    "        for col in range(4):\n",
    "            if count < len(numerical_predictors):\n",
    "                axes[row, col].hist(df[numerical_predictors[count]], bins=50)\n",
    "                axes[row, col].set_title(f\"Column {numerical_predictors[count]}\")\n",
    "                count += 1\n",
    "    if count <= len(numerical_predictors):\n",
    "        axes[row, col].hist(df[output], bins=50)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if \"Instrumentalness\" in df.columns:\n",
    "        instrumental_mean, instrumental_std = df[\"Instrumentalness\"].mean(), df[\"Instrumentalness\"].std()\n",
    "        df['instrumental_binary'] = df[\"Instrumentalness\"].apply(lambda x: 1 if x > instrumental_mean + 1 * instrumental_std or x < instrumental_mean - 1 * instrumental_std else 0)\n",
    "\n",
    "        numerical_predictors.remove(\"Instrumentalness\")\n",
    "        numerical_predictors.append(\"instrumental_binary\")\n",
    "    print(\"Numerical predictors train: \", numerical_predictors)\n",
    "\n",
    "    x_scaler = StandardScaler()\n",
    "    x_scaler.fit(df[numerical_predictors])\n",
    "    df[numerical_predictors] = x_scaler.transform(df[numerical_predictors])\n",
    "\n",
    "    x = df[numerical_predictors].to_numpy()\n",
    "\n",
    "    nrows = int(x.shape[1] / 4) + 1\n",
    "    fig, axes = plt.subplots(nrows, ncols=4, figsize=(60, 20))\n",
    "    count = 0\n",
    "    for row in range(nrows):\n",
    "        for col in range(4):\n",
    "            if count < x.shape[1]:\n",
    "                axes[row, col].hist(x[:, count], bins=50)\n",
    "                axes[row, col].set_title(f\"Column {col}\")\n",
    "                count += 1\n",
    "    # if count <= len(numerical_predictors):\n",
    "    #     axes[row, col].hist(df[output], bins=50)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    y = df[output].to_numpy().ravel() # Use ravel() to ensure y is 1D\n",
    "\n",
    "    pca = None\n",
    "    pca = PCA(n_components=7)\n",
    "    pca.fit(x)\n",
    "    x = pca.transform(x)\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.xticks(range(1, len(explained_variance_ratio) + 1))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(\"PCA explained variance ratio:\", explained_variance_ratio)\n",
    "    print(\"PCA components shape:\", pca.components_.shape)\n",
    "\n",
    "    # TODO if going to add categorical variables, do it here (after)\n",
    "\n",
    "    return x, y, x_scaler, df['mean_views'], pca\n",
    "\n",
    "\n",
    "def get_val_df(df: pd.DataFrame, numerical_predictors: list, categorical_predictors: list, output: str, x_scaler=None, mean_views=None, pca=None):\n",
    "    all_cols = numerical_predictors + categorical_predictors + [output]\n",
    "    df = df.dropna(subset=all_cols).copy()\n",
    "\n",
    "    for col in numerical_predictors:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        df[col] = df[col].apply(lambda x: clip(x, mean, std, 2))\n",
    "\n",
    "    if output == \"Views\":\n",
    "        df[output] = df[output].apply(lambda x: np.sqrt(x))\n",
    "    if 'Duration_ms' in df.columns:\n",
    "        df['Duration_ms'] = df['Duration_ms'].apply(lambda x: np.sqrt(x))\n",
    "    if 'Key' in df.columns:\n",
    "        df['key_angle'] = df['Key'].apply(lambda x: x * 30)\n",
    "        df['key_height'] = df['key_angle'].apply(lambda x: np.sin(np.radians(x)))\n",
    "        df['key_width'] = df['key_angle'].apply(lambda x: np.cos(np.radians(x)))\n",
    "        numerical_predictors.remove(\"Key\")\n",
    "        numerical_predictors.append(\"key_height\")\n",
    "        numerical_predictors.append(\"key_width\")\n",
    "\n",
    "    if mean_views is not None:\n",
    "        df['mean_views'] = df['Artist'].map(mean_views).apply(np.sqrt)\n",
    "    else:\n",
    "        df['mean_views'] = df['Artist'].map(df.groupby('Artist')[output].mean()).apply(np.sqrt)\n",
    "\n",
    "    feature_list = list(numerical_predictors)\n",
    "    if \"Instrumentalness\" in df.columns and \"Instrumentalness\" in feature_list:\n",
    "        instrumental_mean, instrumental_std = df[\"Instrumentalness\"].mean(), df[\"Instrumentalness\"].std()\n",
    "        df['instrumental_binary'] = df[\"Instrumentalness\"].apply(\n",
    "            lambda x: 1 if x > instrumental_mean + 1 * instrumental_std or x < instrumental_mean - 1 * instrumental_std else 0)\n",
    "        feature_list.remove(\"Instrumentalness\")\n",
    "        feature_list.append(\"instrumental_binary\")\n",
    "\n",
    "    if x_scaler is not None:\n",
    "        df[feature_list] = x_scaler.transform(df[feature_list])\n",
    "\n",
    "    x = df[feature_list].to_numpy()\n",
    "\n",
    "    if pca is not None:\n",
    "        x = pca.transform(x)\n",
    "\n",
    "    y = df[output].to_numpy().ravel()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = [\n",
    "    'Danceability',\n",
    "    'Energy',\n",
    "    'Key',\n",
    "    'Loudness',\n",
    "    'Speechiness',\n",
    "    'Acousticness',\n",
    "    'Instrumentalness',\n",
    "    'Liveness', # like energy\n",
    "    'Valence',\n",
    "    'Tempo',\n",
    "    'Duration_ms',\n",
    "]\n",
    "\n",
    "train[cols_to_use].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1365c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cols_to_use = copy.deepcopy(cols_to_use)\n",
    "test_cols_to_use = copy.deepcopy(cols_to_use)\n",
    "train_x_np, train_y_np, x_scaler, mean_views, pca = get_train_df(train, cols_to_use, [], 'Views')\n",
    "\n",
    "val_x_np, val_y_np = get_val_df(val, val_cols_to_use, [], 'Views', x_scaler, mean_views, pca)\n",
    "test_x_np, test_y_np = get_val_df(test, test_cols_to_use, [], 'Views', x_scaler, mean_views, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = int(train_x_np.shape[1] / 4) + 1\n",
    "fig, axes = plt.subplots(nrows, ncols=4, figsize=(60, 20))\n",
    "count = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(4):\n",
    "        if count < train_x_np.shape[1]:\n",
    "            axes[row, col].hist(train_x_np[:, count], bins=50)\n",
    "            axes[row, col].set_title(f\"Column {col}\")\n",
    "            count += 1\n",
    "# if count <= len(numerical_predictors):\n",
    "#     axes[row, col].hist(df[output], bins=50)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "linear_model = LinearRegression().fit(train_x_np, train_y_np)\n",
    "\n",
    "print(\"Model Coefficients:\", linear_model.coef_)\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "poly.fit(train_x_np)\n",
    "train_x_poly = poly.transform(train_x_np)\n",
    "poly_model = LinearRegression().fit(train_x_poly, train_y_np)\n",
    "print(\"Polynomial Model Coefficients:\", poly_model.coef_)\n",
    "\n",
    "\n",
    "# Create and fit the Random Forest Regressor\n",
    "tree = RandomForestRegressor(n_estimators=100)\n",
    "tree.fit(train_x_np, train_y_np)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\", tree.feature_importances_)\n",
    "\n",
    "\n",
    "# print(f\"Model score on train data: {model.score(train_x_np, train_y_np)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def print_scores(y_actual, y_pred, name=str):\n",
    "    mse = mean_squared_error(y_actual, y_pred)\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "\n",
    "    print(f\"{name} Mean Squared Error (Scaled): {mse}\")\n",
    "    print(f\"{name} R^2 Score (Scaled): {r2}\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_actual, y_pred, alpha=0.5)\n",
    "    # ax.plot([y_actual.min(), y_actual.max()], [y_actual.min(), y_actual.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel(\"Actual Views\")\n",
    "    ax.set_ylabel(\"Predicted Views\")\n",
    "    ax.set_title(f\"Actual vs Predicted Scaled Views {name}\")\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print_scores(val_y_np, linear_model.predict(val_x_np), \"Linear Regression\")\n",
    "print_scores(val_y_np, poly_model.predict(poly.transform(val_x_np)), \"Polynomial Regression\")\n",
    "print_scores(val_y_np, tree.predict(val_x_np), \"Random Forest Regression\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "\n",
    "def plot_predications_vs_actual(y_actual, y_pred, number_plotting: int, name: str):\n",
    "    indices = rd.sample(range(len(y_pred)), number_plotting) # Use sample to avoid duplicates\n",
    "\n",
    "    w, x = 0.35, np.arange(number_plotting)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    y_pred_sampled = y_pred[indices]\n",
    "    y_actual_sampled = y_actual[indices]\n",
    "\n",
    "    ax.bar(x - w, y_actual_sampled.squeeze(), width=w, label='Actual')\n",
    "    ax.bar(x, y_pred_sampled.squeeze(), width=w, label=f'Predicted {name}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'Song {i+1}' for i in range(number_plotting)])\n",
    "    ax.set_ylabel(\"Scaled Views\")\n",
    "    ax.set_title(f\"Predicted vs Actual Scaled Views for {number_plotting} Random Samples using {name}\")\n",
    "    ax.legend()\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "number_plotting = 15\n",
    "plot_predications_vs_actual(val_y_np, linear_model.predict(val_x_np), number_plotting, \"Linear\")\n",
    "plot_predications_vs_actual(val_y_np, poly_model.predict(poly.transform(val_x_np)), number_plotting, \"Polynomial\")\n",
    "plot_predications_vs_actual(val_y_np, tree.predict(val_x_np), number_plotting, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc13e6",
   "metadata": {},
   "source": [
    "# Final use of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(test_y_np, tree.predict(test_x_np), \"Tree\")\n",
    "plot_predications_vs_actual(test_y_np, tree.predict(test_x_np), number_plotting, \"Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68058246",
   "metadata": {},
   "source": [
    "# Useful tree plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tree_to_plot = tree.estimators_[0]\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_to_plot, feature_names=cols_to_use, filled=True, rounded=True, fontsize=10)\n",
    "plt.title(\"Decision Tree from Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2db40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
